{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://free.gpt.ge\n",
    "# sk-8jbbIIYpbQPPDdc57288B0Fe9573499582156fCcA330EeD7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "environ{'PATH': '/Users/xiaoleizuo/opt/apache-maven-3.8.6/bin:/Users/xiaoleizuo/go/bin:/Users/xiaoleizuo/opt/anaconda3/bin:/Users/xiaoleizuo/opt/anaconda3/condabin:/opt/homebrew/bin:/opt/homebrew/sbin:/usr/local/bin:/System/Cryptexes/App/usr/bin:/usr/bin:/bin:/usr/sbin:/sbin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/local/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/appleinternal/bin:/Library/Apple/usr/bin:/usr/local/go/bin',\n        'MYSQL_IP': 'gz-cdb-cdumj38l.sql.tencentcdb.com',\n        'CONDA_DEFAULT_ENV': 'base',\n        'CONDA_PYTHON_EXE': '/Users/xiaoleizuo/opt/anaconda3/bin/python',\n        'GATEWAY_VM_OPTIONS': '/Users/xiaoleizuo/Downloads/jihuo-tool-2022.3/jetbra/vmoptions/gateway.vmoptions',\n        'CONDA_PREFIX': '/Users/xiaoleizuo/opt/anaconda3',\n        'RIDER_VM_OPTIONS': '/Users/xiaoleizuo/Downloads/jihuo-tool-2022.3/jetbra/vmoptions/rider.vmoptions',\n        'DEVECOSTUDIO_VM_OPTIONS': '/Users/xiaoleizuo/Downloads/jihuo-tool-2022.3/jetbra/vmoptions/devecostudio.vmoptions',\n        'LOGNAME': 'xiaoleizuo',\n        'STUDIO_VM_OPTIONS': '/Users/xiaoleizuo/Downloads/jihuo-tool-2022.3/jetbra/vmoptions/studio.vmoptions',\n        'PWD': '/Users/xiaoleizuo/workspace/code-reader',\n        'INFOPATH': '/opt/homebrew/share/info:',\n        'LANGUAGE': '',\n        'MYSQL_PASSWORD': 'Zuoxiaolei1990',\n        'SHELL': '/bin/zsh',\n        'APPCODE_VM_OPTIONS': '/Users/xiaoleizuo/Downloads/jihuo-tool-2022.3/jetbra/vmoptions/appcode.vmoptions',\n        'MYSQL_USER': 'root',\n        'OLDPWD': '/',\n        'HOMEBREW_CELLAR': '/opt/homebrew/Cellar',\n        'TMPDIR': '/var/folders/ky/tcc5bn5n0qj_7bwlyfw0xc400000gn/T/',\n        'DATASPELL_VM_OPTIONS': '/Users/xiaoleizuo/Downloads/jihuo-tool-2022.3/jetbra/vmoptions/dataspell.vmoptions',\n        'XPC_FLAGS': '0x0',\n        'LC_ALL': 'en_US.UTF-8',\n        '__CF_USER_TEXT_ENCODING': '0x1F5:0x19:0x34',\n        'CONDA_PROMPT_MODIFIER': '(base) ',\n        'LC_CTYPE': 'zh_CN.UTF-8',\n        'DATAGRIP_VM_OPTIONS': '/Users/xiaoleizuo/Downloads/jihuo-tool-2022.3/jetbra/vmoptions/datagrip.vmoptions',\n        'MANPATH': '/opt/homebrew/share/man::',\n        'PYCHARM_VM_OPTIONS': '/Users/xiaoleizuo/Downloads/jihuo-tool-2022.3/jetbra/vmoptions/pycharm.vmoptions',\n        'WEBSTORM_VM_OPTIONS': '/Users/xiaoleizuo/Downloads/jihuo-tool-2022.3/jetbra/vmoptions/webstorm.vmoptions',\n        'CONDA_EXE': '/Users/xiaoleizuo/opt/anaconda3/bin/conda',\n        'CLION_VM_OPTIONS': '/Users/xiaoleizuo/Downloads/jihuo-tool-2022.3/jetbra/vmoptions/clion.vmoptions',\n        'JETBRAINSCLIENT_VM_OPTIONS': '/Users/xiaoleizuo/Downloads/jihuo-tool-2022.3/jetbra/vmoptions/jetbrainsclient.vmoptions',\n        'HOMEBREW_PREFIX': '/opt/homebrew',\n        'LANG': 'en_US.UTF-8',\n        'COMMAND_MODE': 'unix2003',\n        'MYSQL_PORT': '63635',\n        'GOLAND_VM_OPTIONS': '/Users/xiaoleizuo/Downloads/jihuo-tool-2022.3/jetbra/vmoptions/goland.vmoptions',\n        '_CE_M': '',\n        'IDEA_VM_OPTIONS': '/Users/xiaoleizuo/Downloads/jihuo-tool-2022.3/jetbra/vmoptions/idea.vmoptions',\n        'RUBYMINE_VM_OPTIONS': '/Users/xiaoleizuo/Downloads/jihuo-tool-2022.3/jetbra/vmoptions/rubymine.vmoptions',\n        'JETBRAINS_CLIENT_VM_OPTIONS': '/Users/xiaoleizuo/Downloads/jihuo-tool-2022.3/jetbra/vmoptions/jetbrains_client.vmoptions',\n        'HOMEBREW_REPOSITORY': '/opt/homebrew',\n        'XPC_SERVICE_NAME': 'application.com.jetbrains.pycharm.391691.392371',\n        'CONDA_SHLVL': '1',\n        '__CFBundleIdentifier': 'com.jetbrains.pycharm',\n        'USER': 'xiaoleizuo',\n        'SSH_AUTH_SOCK': '/private/tmp/com.apple.launchd.ffLZLKLxDl/Listeners',\n        '_CE_CONDA': '',\n        'WEBIDE_VM_OPTIONS': '/Users/xiaoleizuo/Downloads/jihuo-tool-2022.3/jetbra/vmoptions/webide.vmoptions',\n        'PHPSTORM_VM_OPTIONS': '/Users/xiaoleizuo/Downloads/jihuo-tool-2022.3/jetbra/vmoptions/phpstorm.vmoptions',\n        'HOME': '/Users/xiaoleizuo',\n        'PYDEVD_USE_FRAME_EVAL': 'NO',\n        'JPY_PARENT_PID': '99686',\n        'TERM': 'xterm-color',\n        'CLICOLOR': '1',\n        'PAGER': 'cat',\n        'GIT_PAGER': 'cat',\n        'MPLBACKEND': 'module://matplotlib_inline.backend_inline'}"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiaoleizuo/opt/anaconda3/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", max_tokens=16385,\n",
    "             openai_api_key='sk-pIhsi7T7vv8PZe4aYKGUeWaUmuX3TJQ4fPqQx7GrySPvFDOU',\n",
    "             openai_api_base='https://api.chatanywhere.tech/v1')\n",
    "from langchain.globals import set_debug\n",
    "\n",
    "set_debug(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32;1m\u001B[1;3m[llm/start]\u001B[0m \u001B[1m[1:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001B[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: 怎么评价人工智能?\"\n",
      "  ]\n",
      "}\n",
      "人工智能是一项具有巨大潜力和广泛应用的技术。它通过模拟人类智能的能力，使机器能够学习、理解、推理和执行任务。以下是对人工智能的一些评价：\n",
      "\n",
      "1. 创新和发展潜力：人工智能的发展具有巨大的潜力，可以在各个领域实现创新解决方案。它可以提供更高效、更准确、更快速的数据分析、决策支持和问题解决能力。\n",
      "\n",
      "2. 自动化和效率提升：人工智能可以自动执行繁琐、重复和机械的任务，从而提高工作效率，减少人力成本，并释放人类的创造力和创新能力。\n",
      "\n",
      "3. 数据处理和智能分析：人工智能可以处理和分析大量的数据，从中提取有价值的信息和洞察，并帮助做出准确的预测和决策。\n",
      "\n",
      "4. 个人隐私和伦理问题：人工智能的发展也引发了一些关于个人隐私和伦理问题的担忧。例如，人工智能可能会收集和使用个人数据，引发数据安全和隐私泄露的风险。\n",
      "\n",
      "5. 就业和社会影响：人工智能的广泛应用可能会对某些行业和工作岗位产生冲击，导致部分人失去工作。因此，需要采取措施来应对潜在的就业问题，并确保人工智能的发展符合社会的利益。\n",
      "\n",
      "总体而言，人工智能是一项具有巨大潜力和挑战的技术，需要在科技和伦理等方面的平衡中发展和应用。\u001B[36;1m\u001B[1;3m[llm/end]\u001B[0m \u001B[1m[1:llm:ChatOpenAI] [14.65s] Exiting LLM run with output:\n",
      "\u001B[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"人工智能是一项具有巨大潜力和广泛应用的技术。它通过模拟人类智能的能力，使机器能够学习、理解、推理和执行任务。以下是对人工智能的一些评价：\\n\\n1. 创新和发展潜力：人工智能的发展具有巨大的潜力，可以在各个领域实现创新解决方案。它可以提供更高效、更准确、更快速的数据分析、决策支持和问题解决能力。\\n\\n2. 自动化和效率提升：人工智能可以自动执行繁琐、重复和机械的任务，从而提高工作效率，减少人力成本，并释放人类的创造力和创新能力。\\n\\n3. 数据处理和智能分析：人工智能可以处理和分析大量的数据，从中提取有价值的信息和洞察，并帮助做出准确的预测和决策。\\n\\n4. 个人隐私和伦理问题：人工智能的发展也引发了一些关于个人隐私和伦理问题的担忧。例如，人工智能可能会收集和使用个人数据，引发数据安全和隐私泄露的风险。\\n\\n5. 就业和社会影响：人工智能的广泛应用可能会对某些行业和工作岗位产生冲击，导致部分人失去工作。因此，需要采取措施来应对潜在的就业问题，并确保人工智能的发展符合社会的利益。\\n\\n总体而言，人工智能是一项具有巨大潜力和挑战的技术，需要在科技和伦理等方面的平衡中发展和应用。\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        },\n",
      "        \"type\": \"ChatGenerationChunk\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessageChunk\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"人工智能是一项具有巨大潜力和广泛应用的技术。它通过模拟人类智能的能力，使机器能够学习、理解、推理和执行任务。以下是对人工智能的一些评价：\\n\\n1. 创新和发展潜力：人工智能的发展具有巨大的潜力，可以在各个领域实现创新解决方案。它可以提供更高效、更准确、更快速的数据分析、决策支持和问题解决能力。\\n\\n2. 自动化和效率提升：人工智能可以自动执行繁琐、重复和机械的任务，从而提高工作效率，减少人力成本，并释放人类的创造力和创新能力。\\n\\n3. 数据处理和智能分析：人工智能可以处理和分析大量的数据，从中提取有价值的信息和洞察，并帮助做出准确的预测和决策。\\n\\n4. 个人隐私和伦理问题：人工智能的发展也引发了一些关于个人隐私和伦理问题的担忧。例如，人工智能可能会收集和使用个人数据，引发数据安全和隐私泄露的风险。\\n\\n5. 就业和社会影响：人工智能的广泛应用可能会对某些行业和工作岗位产生冲击，导致部分人失去工作。因此，需要采取措施来应对潜在的就业问题，并确保人工智能的发展符合社会的利益。\\n\\n总体而言，人工智能是一项具有巨大潜力和挑战的技术，需要在科技和伦理等方面的平衡中发展和应用。\",\n",
      "            \"example\": false,\n",
      "            \"additional_kwargs\": {},\n",
      "            \"tool_call_chunks\": [],\n",
      "            \"response_metadata\": {\n",
      "              \"finish_reason\": \"stop\"\n",
      "            },\n",
      "            \"id\": \"run-5214fda7-3790-4b82-887d-3d35ed43864e\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "llm_answer = llm.stream(\"怎么评价人工智能?\")\n",
    "for ele in llm_answer:\n",
    "    print(ele.content, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object BaseLLM.stream at 0x10d6d6970>\n"
     ]
    }
   ],
   "source": [
    "print(llm_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import DuckDuckGoSearchResults, DuckDuckGoSearchRun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "search = DuckDuckGoSearchResults()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32;1m\u001B[1;3m[tool/start]\u001B[0m \u001B[1m[1:tool:duckduckgo_results_json] Entering Tool run with input:\n",
      "\u001B[0m\"邓紫棋最新的演唱会?\"\n",
      "\u001B[36;1m\u001B[1;3m[tool/end]\u001B[0m \u001B[1m[1:tool:duckduckgo_results_json] [2.68s] Exiting Tool run with output:\n",
      "\u001B[0m\"[snippet: 2024邓紫棋长沙演唱会预售时间. g.e.m.邓紫棋i am gloria世界巡回演唱会，4月13日长沙站2月28日12:00大麦、纷玩岛同步开启预售，详情请见正文。 2024邓紫棋长沙演唱会怎么去？（演出地址+交通指南） 2024年邓紫棋长沙演唱会将于4月13日至4月14日在长沙贺龙体育场举办 ..., title: 2024邓紫棋长沙演唱会预售指南（票价＋时间）- 长沙本地宝, link: http://cs.bendibao.com/xiuxian/2024226/119083.shtm], [snippet: 4月12日至4月14日，2024邓紫棋巡回演唱会长沙站在长沙贺龙体育中心举行，演唱会首日，场外骚乱不断引发网友关注。4月16日中午，邓紫棋长沙演唱会主办方湖南稻康文化回应了本次演唱会中出现骚乱的原因。据现场观众拍摄的视频显示，12日当晚在演唱会开始检票后，突然有许多观众在高喊\"退票 ..., title: 邓紫棋长沙演唱会场外骚动不断到底咋回事？主办方最新回应, link: https://new.qq.com/rain/a/20240417A059KP00], [snippet: 邓紫棋 I AM GLORIA 演唱会 长沙站 5.12 Day1拍摄设备：JDI Pocket3收音模式：前向收音。减少了自己瞎BB的杂音，但现场大合唱收音效果也受到了影响——————抢到票的时候很激动，立马请好了假定好了酒店，从杭州跑到了长沙，看了一场，蹭了一场场外，顺便特种兵旅游, 视频播放量 17、弹幕量 0、点 ..., title: 【I AM GLORIA】邓紫棋长沙演唱会Day1——Part1 - 哔哩哔哩, link: https://www.bilibili.com/video/BV1dJ4m1V7iL/], [snippet: 4月12至14日，\"2024邓紫棋巡回演唱会-长沙站\"在长沙贺龙体育中心举行。通知要求\"大型营业性演出活动实行实名购票和实名入场制度，每场演出每个身份证件只能购买一张门票，购票人与入场人身份信息保持一致。根据《通知》要求，我们把本次演唱会门票的总数的85%，在大麦网、纷玩岛、爱 ..., title: 邓紫棋演唱会长沙站出现了\"错票\"？主办方回应!, link: https://m.gmw.cn/2024-04/16/content_1303714317.htm]\"\n"
     ]
    },
    {
     "data": {
      "text/plain": "'[snippet: 2024邓紫棋长沙演唱会预售时间. g.e.m.邓紫棋i am gloria世界巡回演唱会，4月13日长沙站2月28日12:00大麦、纷玩岛同步开启预售，详情请见正文。 2024邓紫棋长沙演唱会怎么去？（演出地址+交通指南） 2024年邓紫棋长沙演唱会将于4月13日至4月14日在长沙贺龙体育场举办 ..., title: 2024邓紫棋长沙演唱会预售指南（票价＋时间）- 长沙本地宝, link: http://cs.bendibao.com/xiuxian/2024226/119083.shtm], [snippet: 4月12日至4月14日，2024邓紫棋巡回演唱会长沙站在长沙贺龙体育中心举行，演唱会首日，场外骚乱不断引发网友关注。4月16日中午，邓紫棋长沙演唱会主办方湖南稻康文化回应了本次演唱会中出现骚乱的原因。据现场观众拍摄的视频显示，12日当晚在演唱会开始检票后，突然有许多观众在高喊\"退票 ..., title: 邓紫棋长沙演唱会场外骚动不断到底咋回事？主办方最新回应, link: https://new.qq.com/rain/a/20240417A059KP00], [snippet: 邓紫棋 I AM GLORIA 演唱会 长沙站 5.12 Day1拍摄设备：JDI Pocket3收音模式：前向收音。减少了自己瞎BB的杂音，但现场大合唱收音效果也受到了影响——————抢到票的时候很激动，立马请好了假定好了酒店，从杭州跑到了长沙，看了一场，蹭了一场场外，顺便特种兵旅游, 视频播放量 17、弹幕量 0、点 ..., title: 【I AM GLORIA】邓紫棋长沙演唱会Day1——Part1 - 哔哩哔哩, link: https://www.bilibili.com/video/BV1dJ4m1V7iL/], [snippet: 4月12至14日，\"2024邓紫棋巡回演唱会-长沙站\"在长沙贺龙体育中心举行。通知要求\"大型营业性演出活动实行实名购票和实名入场制度，每场演出每个身份证件只能购买一张门票，购票人与入场人身份信息保持一致。根据《通知》要求，我们把本次演唱会门票的总数的85%，在大麦网、纷玩岛、爱 ..., title: 邓紫棋演唱会长沙站出现了\"错票\"？主办方回应!, link: https://m.gmw.cn/2024-04/16/content_1303714317.htm]'"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.run(\"邓紫棋最新的演唱会?\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for SerpAPIWrapper\n__root__\n  Did not find serpapi_api_key, please add an environment variable `SERPAPI_API_KEY` which contains it, or pass `serpapi_api_key` as a named parameter. (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValidationError\u001B[0m                           Traceback (most recent call last)",
      "Input \u001B[0;32mIn [10]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlangchain\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01magents\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m load_tools\n\u001B[0;32m----> 2\u001B[0m tools \u001B[38;5;241m=\u001B[39m \u001B[43mload_tools\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mserpapi\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/langchain/agents/load_tools.py:681\u001B[0m, in \u001B[0;36mload_tools\u001B[0;34m(tool_names, llm, callbacks, allow_dangerous_tools, **kwargs)\u001B[0m\n\u001B[1;32m    679\u001B[0m     _get_tool_func, extra_keys \u001B[38;5;241m=\u001B[39m _EXTRA_OPTIONAL_TOOLS[name]\n\u001B[1;32m    680\u001B[0m     sub_kwargs \u001B[38;5;241m=\u001B[39m {k: kwargs[k] \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m extra_keys \u001B[38;5;28;01mif\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m kwargs}\n\u001B[0;32m--> 681\u001B[0m     tool \u001B[38;5;241m=\u001B[39m \u001B[43m_get_tool_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43msub_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    682\u001B[0m     tools\u001B[38;5;241m.\u001B[39mappend(tool)\n\u001B[1;32m    683\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/langchain/agents/load_tools.py:335\u001B[0m, in \u001B[0;36m_get_serpapi\u001B[0;34m(**kwargs)\u001B[0m\n\u001B[1;32m    331\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_get_serpapi\u001B[39m(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m BaseTool:\n\u001B[1;32m    332\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m Tool(\n\u001B[1;32m    333\u001B[0m         name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSearch\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    334\u001B[0m         description\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mA search engine. Useful for when you need to answer questions about current events. Input should be a search query.\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m--> 335\u001B[0m         func\u001B[38;5;241m=\u001B[39m\u001B[43mSerpAPIWrapper\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mrun,\n\u001B[1;32m    336\u001B[0m         coroutine\u001B[38;5;241m=\u001B[39mSerpAPIWrapper(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\u001B[38;5;241m.\u001B[39marun,\n\u001B[1;32m    337\u001B[0m     )\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pydantic/v1/main.py:341\u001B[0m, in \u001B[0;36mBaseModel.__init__\u001B[0;34m(__pydantic_self__, **data)\u001B[0m\n\u001B[1;32m    339\u001B[0m values, fields_set, validation_error \u001B[38;5;241m=\u001B[39m validate_model(__pydantic_self__\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m, data)\n\u001B[1;32m    340\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m validation_error:\n\u001B[0;32m--> 341\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m validation_error\n\u001B[1;32m    342\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    343\u001B[0m     object_setattr(__pydantic_self__, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m__dict__\u001B[39m\u001B[38;5;124m'\u001B[39m, values)\n",
      "\u001B[0;31mValidationError\u001B[0m: 1 validation error for SerpAPIWrapper\n__root__\n  Did not find serpapi_api_key, please add an environment variable `SERPAPI_API_KEY` which contains it, or pass `serpapi_api_key` as a named parameter. (type=value_error)"
     ]
    }
   ],
   "source": [
    "from langchain.agents import load_tools\n",
    "tools = load_tools([\"serpapi\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "from langchain.agents import create_react_agent\n",
    "from langchain.agents import AgentType"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from langchain import hub"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "tools = [DuckDuckGoSearchResults()]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "prompt = hub.pull(\"hwchase17/react\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "create_react_agent() got an unexpected keyword argument 'agent'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [18]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m agent \u001B[38;5;241m=\u001B[39m \u001B[43mcreate_react_agent\u001B[49m\u001B[43m(\u001B[49m\u001B[43mllm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtools\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43magent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mAgentType\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mZERO_SHOT_REACT_DESCRIPTION\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mTypeError\u001B[0m: create_react_agent() got an unexpected keyword argument 'agent'"
     ]
    }
   ],
   "source": [
    "agent = create_react_agent(llm, tools, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "# from langchain.agents import AgentExecutor\n",
    "# agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[1:chain:AgentExecutor] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"邓紫棋最新的演唱会?\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[1:chain:AgentExecutor > 2:chain:LLMChain] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"邓紫棋最新的演唱会?\",\n",
      "  \"agent_scratchpad\": \"\",\n",
      "  \"stop\": [\n",
      "    \"\\nObservation:\",\n",
      "    \"\\n\\tObservation:\"\n",
      "  ]\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[llm/start]\u001B[0m \u001B[1m[1:chain:AgentExecutor > 2:chain:LLMChain > 3:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001B[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Answer the following questions as best you can. You have access to the following tools:\\n\\nduckduckgo_results_json: A wrapper around Duck Duck Go Search. Useful for when you need to answer questions about current events. Input should be a search query. Output is a JSON array of the query results\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [duckduckgo_results_json]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: 邓紫棋最新的演唱会?\\nThought:\"\n",
      "  ]\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[llm/end]\u001B[0m \u001B[1m[1:chain:AgentExecutor > 2:chain:LLMChain > 3:llm:ChatOpenAI] [1.98s] Exiting LLM run with output:\n",
      "\u001B[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"I should search for the latest concert by 邓紫棋.\\nAction: duckduckgo_results_json\\nAction Input: \\\"邓紫棋最新的演唱会\\\"\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"I should search for the latest concert by 邓紫棋.\\nAction: duckduckgo_results_json\\nAction Input: \\\"邓紫棋最新的演唱会\\\"\",\n",
      "            \"additional_kwargs\": {},\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 188,\n",
      "      \"completion_tokens\": 43,\n",
      "      \"total_tokens\": 231\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[1:chain:AgentExecutor > 2:chain:LLMChain] [1.98s] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"text\": \"I should search for the latest concert by 邓紫棋.\\nAction: duckduckgo_results_json\\nAction Input: \\\"邓紫棋最新的演唱会\\\"\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[tool/start]\u001B[0m \u001B[1m[1:chain:AgentExecutor > 4:tool:duckduckgo_results_json] Entering Tool run with input:\n",
      "\u001B[0m\"邓紫棋最新的演唱会\"\n",
      "\u001B[36;1m\u001B[1;3m[tool/end]\u001B[0m \u001B[1m[1:chain:AgentExecutor > 4:tool:duckduckgo_results_json] [3.74s] Exiting Tool run with output:\n",
      "\u001B[0m\"[snippet: 【1080P60帧】G.E.M 邓紫棋-I AM GLORIA世界巡回演唱会长沙站2024.4.12共计25条视频，包括：1摩天动物园+灰狼、talking1、2来自天堂的魔鬼等，UP主更多精彩视频，请关注UP账号。 ... 4K杜比邓紫棋长沙演唱会：夜的尽头+倒数+新的心跳+G.E.M.remixWalkonWater+泡沫+情人+天空没有 ..., title: 【1080P60帧】G.E.M 邓紫棋-I AM GLORIA世界巡回演唱会长沙站2024.4.12_哔哩哔哩_bilibili, link: https://www.bilibili.com/video/BV1kr421V7S2/], [snippet: 2024邓紫棋长沙演唱会预售时间. g.e.m.邓紫棋i am gloria世界巡回演唱会，4月13日长沙站2月28日12:00大麦、纷玩岛同步开启预售，详情请见正文。 2024邓紫棋长沙演唱会怎么去？（演出地址+交通指南） 2024年邓紫棋长沙演唱会将于4月13日至4月14日在长沙贺龙体育场举办 ..., title: 2024邓紫棋长沙演唱会预售指南（票价＋时间）- 长沙本地宝, link: http://cs.bendibao.com/xiuxian/2024226/119083.shtm], [snippet: \"铁肺女王\"邓紫棋7月最新世界巡回演唱会《I AM GLORIA》正式官宣，首站将于12月9日在广州强势开跑! 本次巡演以邓紫棋的本名GLORIA作为主题，8日她晒出演唱会官方海报，并一口气官宣了广州、深圳、南宁、泉州四站，写道：\"久等了!I AM GLORIA巡演，真的来了!好兴奋!黑暗中的曙光，乱世中的 ..., title: 官宣!邓紫棋最新《I AM GLORIA》世巡12月开跑! - Woah.MY, link: https://www.woah.my/2023/11/08/guan-xuan-deng-zi-qi-zui-xin/], [snippet: 邓紫棋长沙演唱会4.14全场4k共计21条视频，包括：Part1 开场动画＋摩天动物园＋灰狼、来自天堂的魔鬼、Talk1＋光年之外等，UP主更多精彩视频，请关注UP账号。 ... 【时光2】田震评价邓紫棋《你不是第一个离开的人》张力 ... BABYMONSTER最新回归曲SHEESH 240411打歌舞台 ..., title: 邓紫棋长沙演唱会4.14全场4k_哔哩哔哩_bilibili, link: https://www.bilibili.com/video/BV1hM4m1D7ga/]\"\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[1:chain:AgentExecutor > 5:chain:LLMChain] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"邓紫棋最新的演唱会?\",\n",
      "  \"agent_scratchpad\": \"I should search for the latest concert by 邓紫棋.\\nAction: duckduckgo_results_json\\nAction Input: \\\"邓紫棋最新的演唱会\\\"\\nObservation: [snippet: 【1080P60帧】G.E.M 邓紫棋-I AM GLORIA世界巡回演唱会长沙站2024.4.12共计25条视频，包括：1摩天动物园+灰狼、talking1、2来自天堂的魔鬼等，UP主更多精彩视频，请关注UP账号。 ... 4K杜比邓紫棋长沙演唱会：夜的尽头+倒数+新的心跳+G.E.M.remixWalkonWater+泡沫+情人+天空没有 ..., title: 【1080P60帧】G.E.M 邓紫棋-I AM GLORIA世界巡回演唱会长沙站2024.4.12_哔哩哔哩_bilibili, link: https://www.bilibili.com/video/BV1kr421V7S2/], [snippet: 2024邓紫棋长沙演唱会预售时间. g.e.m.邓紫棋i am gloria世界巡回演唱会，4月13日长沙站2月28日12:00大麦、纷玩岛同步开启预售，详情请见正文。 2024邓紫棋长沙演唱会怎么去？（演出地址+交通指南） 2024年邓紫棋长沙演唱会将于4月13日至4月14日在长沙贺龙体育场举办 ..., title: 2024邓紫棋长沙演唱会预售指南（票价＋时间）- 长沙本地宝, link: http://cs.bendibao.com/xiuxian/2024226/119083.shtm], [snippet: \\\"铁肺女王\\\"邓紫棋7月最新世界巡回演唱会《I AM GLORIA》正式官宣，首站将于12月9日在广州强势开跑! 本次巡演以邓紫棋的本名GLORIA作为主题，8日她晒出演唱会官方海报，并一口气官宣了广州、深圳、南宁、泉州四站，写道：\\\"久等了!I AM GLORIA巡演，真的来了!好兴奋!黑暗中的曙光，乱世中的 ..., title: 官宣!邓紫棋最新《I AM GLORIA》世巡12月开跑! - Woah.MY, link: https://www.woah.my/2023/11/08/guan-xuan-deng-zi-qi-zui-xin/], [snippet: 邓紫棋长沙演唱会4.14全场4k共计21条视频，包括：Part1 开场动画＋摩天动物园＋灰狼、来自天堂的魔鬼、Talk1＋光年之外等，UP主更多精彩视频，请关注UP账号。 ... 【时光2】田震评价邓紫棋《你不是第一个离开的人》张力 ... BABYMONSTER最新回归曲SHEESH 240411打歌舞台 ..., title: 邓紫棋长沙演唱会4.14全场4k_哔哩哔哩_bilibili, link: https://www.bilibili.com/video/BV1hM4m1D7ga/]\\nThought:\",\n",
      "  \"stop\": [\n",
      "    \"\\nObservation:\",\n",
      "    \"\\n\\tObservation:\"\n",
      "  ]\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[llm/start]\u001B[0m \u001B[1m[1:chain:AgentExecutor > 5:chain:LLMChain > 6:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001B[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Answer the following questions as best you can. You have access to the following tools:\\n\\nduckduckgo_results_json: A wrapper around Duck Duck Go Search. Useful for when you need to answer questions about current events. Input should be a search query. Output is a JSON array of the query results\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [duckduckgo_results_json]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: 邓紫棋最新的演唱会?\\nThought:I should search for the latest concert by 邓紫棋.\\nAction: duckduckgo_results_json\\nAction Input: \\\"邓紫棋最新的演唱会\\\"\\nObservation: [snippet: 【1080P60帧】G.E.M 邓紫棋-I AM GLORIA世界巡回演唱会长沙站2024.4.12共计25条视频，包括：1摩天动物园+灰狼、talking1、2来自天堂的魔鬼等，UP主更多精彩视频，请关注UP账号。 ... 4K杜比邓紫棋长沙演唱会：夜的尽头+倒数+新的心跳+G.E.M.remixWalkonWater+泡沫+情人+天空没有 ..., title: 【1080P60帧】G.E.M 邓紫棋-I AM GLORIA世界巡回演唱会长沙站2024.4.12_哔哩哔哩_bilibili, link: https://www.bilibili.com/video/BV1kr421V7S2/], [snippet: 2024邓紫棋长沙演唱会预售时间. g.e.m.邓紫棋i am gloria世界巡回演唱会，4月13日长沙站2月28日12:00大麦、纷玩岛同步开启预售，详情请见正文。 2024邓紫棋长沙演唱会怎么去？（演出地址+交通指南） 2024年邓紫棋长沙演唱会将于4月13日至4月14日在长沙贺龙体育场举办 ..., title: 2024邓紫棋长沙演唱会预售指南（票价＋时间）- 长沙本地宝, link: http://cs.bendibao.com/xiuxian/2024226/119083.shtm], [snippet: \\\"铁肺女王\\\"邓紫棋7月最新世界巡回演唱会《I AM GLORIA》正式官宣，首站将于12月9日在广州强势开跑! 本次巡演以邓紫棋的本名GLORIA作为主题，8日她晒出演唱会官方海报，并一口气官宣了广州、深圳、南宁、泉州四站，写道：\\\"久等了!I AM GLORIA巡演，真的来了!好兴奋!黑暗中的曙光，乱世中的 ..., title: 官宣!邓紫棋最新《I AM GLORIA》世巡12月开跑! - Woah.MY, link: https://www.woah.my/2023/11/08/guan-xuan-deng-zi-qi-zui-xin/], [snippet: 邓紫棋长沙演唱会4.14全场4k共计21条视频，包括：Part1 开场动画＋摩天动物园＋灰狼、来自天堂的魔鬼、Talk1＋光年之外等，UP主更多精彩视频，请关注UP账号。 ... 【时光2】田震评价邓紫棋《你不是第一个离开的人》张力 ... BABYMONSTER最新回归曲SHEESH 240411打歌舞台 ..., title: 邓紫棋长沙演唱会4.14全场4k_哔哩哔哩_bilibili, link: https://www.bilibili.com/video/BV1hM4m1D7ga/]\\nThought:\"\n",
      "  ]\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[llm/end]\u001B[0m \u001B[1m[1:chain:AgentExecutor > 5:chain:LLMChain > 6:llm:ChatOpenAI] [4.35s] Exiting LLM run with output:\n",
      "\u001B[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"The latest concert by 邓紫棋 is titled \\\"G.E.M 邓紫棋-I AM GLORIA世界巡回演唱会长沙站2024.4.12\\\" and it took place on April 12, 2024 in Changsha. There are also upcoming concerts in other cities like Guangzhou, Shenzhen, Nanning, and Quanzhou.\\nFinal Answer: 邓紫棋最新的演唱会是\\\"G.E.M 邓紫棋-I AM GLORIA世界巡回演唱会长沙站2024.4.12\\\" (G.E.M 邓紫棋-I AM GLORIA World Tour Concert Changsha Station 2024.4.12)\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"The latest concert by 邓紫棋 is titled \\\"G.E.M 邓紫棋-I AM GLORIA世界巡回演唱会长沙站2024.4.12\\\" and it took place on April 12, 2024 in Changsha. There are also upcoming concerts in other cities like Guangzhou, Shenzhen, Nanning, and Quanzhou.\\nFinal Answer: 邓紫棋最新的演唱会是\\\"G.E.M 邓紫棋-I AM GLORIA世界巡回演唱会长沙站2024.4.12\\\" (G.E.M 邓紫棋-I AM GLORIA World Tour Concert Changsha Station 2024.4.12)\",\n",
      "            \"additional_kwargs\": {},\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 1179,\n",
      "      \"completion_tokens\": 173,\n",
      "      \"total_tokens\": 1352\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[1:chain:AgentExecutor > 5:chain:LLMChain] [4.36s] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"text\": \"The latest concert by 邓紫棋 is titled \\\"G.E.M 邓紫棋-I AM GLORIA世界巡回演唱会长沙站2024.4.12\\\" and it took place on April 12, 2024 in Changsha. There are also upcoming concerts in other cities like Guangzhou, Shenzhen, Nanning, and Quanzhou.\\nFinal Answer: 邓紫棋最新的演唱会是\\\"G.E.M 邓紫棋-I AM GLORIA世界巡回演唱会长沙站2024.4.12\\\" (G.E.M 邓紫棋-I AM GLORIA World Tour Concert Changsha Station 2024.4.12)\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[1:chain:AgentExecutor] [10.09s] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": \"邓紫棋最新的演唱会是\\\"G.E.M 邓紫棋-I AM GLORIA世界巡回演唱会长沙站2024.4.12\\\" (G.E.M 邓紫棋-I AM GLORIA World Tour Concert Changsha Station 2024.4.12)\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'input': '邓紫棋最新的演唱会?',\n 'output': '邓紫棋最新的演唱会是\"G.E.M 邓紫棋-I AM GLORIA世界巡回演唱会长沙站2024.4.12\" (G.E.M 邓紫棋-I AM GLORIA World Tour Concert Changsha Station 2024.4.12)'}"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\"邓紫棋最新的演唱会?\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "loader = UnstructuredFileLoader(\"/Users/xiaoleizuo/opt/anaconda3/lib/python3.9/site-packages/langchain_community/llms/baichuan.py\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "document = loader.load()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "[Document(page_content='from __future__ import annotations\\n\\nimport json import logging from typing import Any, Dict, List, Optional\\n\\nimport requests from langchain_core.callbacks import CallbackManagerForLLMRun from langchain_core.language_models.llms import LLM from langchain_core.pydantic_v1 import Field, SecretStr, root_validator from langchain_core.utils import convert_to_secret_str, get_from_dict_or_env\\n\\nfrom langchain_community.llms.utils import enforce_stop_tokens\\n\\nlogger = logging.getLogger(__name__)\\n\\nclass BaichuanLLM(LLM): # TODO: Adding streaming support. \"\"\"Wrapper around Baichuan large language models.\"\"\"\\n\\nmodel: str = \"Baichuan2-Turbo-192k\" \"\"\" Other models are available at https://platform.baichuan-ai.com/docs/api. \"\"\" temperature: float = 0.3 top_p: float = 0.95 timeout: int = 60 model_kwargs: Dict[str, Any] = Field(default_factory=dict)\\n\\nbaichuan_api_host: Optional[str] = None\\n\\nbaichuan_api_key: Optional[SecretStr] = None\\n\\n@root_validator()\\n\\ndef validate_environment(cls, values: Dict)\\n\\n\\n\\n> Dict:\\n\\nvalues[\"baichuan_api_key\"] = convert_to_secret_str(\\n\\nget_from_dict_or_env(values, \"baichuan_api_key\", \"BAICHUAN_API_KEY\")\\n\\n)\\n\\nvalues[\"baichuan_api_host\"] = get_from_dict_or_env(\\n\\nvalues,\\n\\n\"baichuan_api_host\",\\n\\n\"BAICHUAN_API_HOST\",\\n\\ndefault=\"https://api.baichuan\\n\\n\\n\\nai.com/v1/chat/completions\",\\n\\n)\\n\\nreturn values\\n\\n@property\\n\\ndef _default_params(self)\\n\\n\\n\\n> Dict[str, Any]:\\n\\nreturn {\\n\\n\"model\": self.model,\\n\\n\"temperature\": self.temperature,\\n\\n\"top_p\": self.top_p,\\n\\n\\n\\n\\n\\nself.model_kwargs,\\n\\n}\\n\\ndef _post(self, request: Any) -> Any: headers = { \"Content-Type\": \"application/json\", \"Authorization\": f\"Bearer {self.baichuan_api_key.get_secret_value()}\",  # type: ignore[union-attr] } try: response = requests.post( self.baichuan_api_host,  # type: ignore[arg-type] headers=headers, json=request, timeout=self.timeout, )\\n\\nif response.status_code == 200: parsed_json = json.loads(response.text) return parsed_json[\"choices\"][0][\"message\"][\"content\"] else: response.raise_for_status() except Exception as e: raise ValueError(f\"An error has occurred: {e}\")\\n\\ndef _call( self, prompt: str, stop: Optional[List[str]] = None, run_manager: Optional[CallbackManagerForLLMRun] = None, **kwargs: Any, ) -> str: request = self._default_params request[\"messages\"] = [{\"role\": \"user\", \"content\": prompt}] request.update(kwargs) text = self._post(request) if stop is not None: text = enforce_stop_tokens(text, stop) return text\\n\\n@property\\n\\ndef _llm_type(self)\\n\\n\\n\\n> str:\\n\\n\"\"\"Return type of chat_model.\"\"\"\\n\\nreturn \"baichuan\\n\\n\\n\\nllm\"', metadata={'source': '/Users/xiaoleizuo/opt/anaconda3/lib/python3.9/site-packages/langchain_community/llms/baichuan.py'})]"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap = 0\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "split_documents = text_splitter.split_documents(document)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "3"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(split_documents)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "chain = load_summarize_chain(llm, chain_type=\"refine\", verbose=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[1:chain:RefineDocumentsChain] Entering Chain run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[1:chain:RefineDocumentsChain > 2:chain:LLMChain] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"text\": \"from __future__ import annotations\\n\\nimport json import logging from typing import Any, Dict, List, Optional\\n\\nimport requests from langchain_core.callbacks import CallbackManagerForLLMRun from langchain_core.language_models.llms import LLM from langchain_core.pydantic_v1 import Field, SecretStr, root_validator from langchain_core.utils import convert_to_secret_str, get_from_dict_or_env\\n\\nfrom langchain_community.llms.utils import enforce_stop_tokens\\n\\nlogger = logging.getLogger(__name__)\\n\\nclass BaichuanLLM(LLM): # TODO: Adding streaming support. \\\"\\\"\\\"Wrapper around Baichuan large language models.\\\"\\\"\\\"\\n\\nmodel: str = \\\"Baichuan2-Turbo-192k\\\" \\\"\\\"\\\" Other models are available at https://platform.baichuan-ai.com/docs/api. \\\"\\\"\\\" temperature: float = 0.3 top_p: float = 0.95 timeout: int = 60 model_kwargs: Dict[str, Any] = Field(default_factory=dict)\\n\\nbaichuan_api_host: Optional[str] = None\\n\\nbaichuan_api_key: Optional[SecretStr] = None\\n\\n@root_validator()\\n\\ndef validate_environment(cls, values: Dict)\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[llm/start]\u001B[0m \u001B[1m[1:chain:RefineDocumentsChain > 2:chain:LLMChain > 3:llm:OpenAIChat] Entering LLM run with input:\n",
      "\u001B[0m{\n",
      "  \"prompts\": [\n",
      "    \"Write a concise summary of the following:\\n\\n\\n\\\"from __future__ import annotations\\n\\nimport json import logging from typing import Any, Dict, List, Optional\\n\\nimport requests from langchain_core.callbacks import CallbackManagerForLLMRun from langchain_core.language_models.llms import LLM from langchain_core.pydantic_v1 import Field, SecretStr, root_validator from langchain_core.utils import convert_to_secret_str, get_from_dict_or_env\\n\\nfrom langchain_community.llms.utils import enforce_stop_tokens\\n\\nlogger = logging.getLogger(__name__)\\n\\nclass BaichuanLLM(LLM): # TODO: Adding streaming support. \\\"\\\"\\\"Wrapper around Baichuan large language models.\\\"\\\"\\\"\\n\\nmodel: str = \\\"Baichuan2-Turbo-192k\\\" \\\"\\\"\\\" Other models are available at https://platform.baichuan-ai.com/docs/api. \\\"\\\"\\\" temperature: float = 0.3 top_p: float = 0.95 timeout: int = 60 model_kwargs: Dict[str, Any] = Field(default_factory=dict)\\n\\nbaichuan_api_host: Optional[str] = None\\n\\nbaichuan_api_key: Optional[SecretStr] = None\\n\\n@root_validator()\\n\\ndef validate_environment(cls, values: Dict)\\\"\\n\\n\\nCONCISE SUMMARY:\"\n",
      "  ]\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[llm/end]\u001B[0m \u001B[1m[1:chain:RefineDocumentsChain > 2:chain:LLMChain > 3:llm:OpenAIChat] [20.93s] Exiting LLM run with output:\n",
      "\u001B[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"This Python code snippet defines a class `BaichuanLLM` that serves as a wrapper around Baichuan large language models. It imports necessary modules, sets up parameters for the model, and includes methods for validation. The class includes attributes for model configuration and API access, with methods for environmental validation. Additionally, it aims to add streaming support in the future.\",\n",
      "        \"generation_info\": null,\n",
      "        \"type\": \"Generation\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 332,\n",
      "      \"completion_tokens\": 74,\n",
      "      \"total_tokens\": 406\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[1:chain:RefineDocumentsChain > 2:chain:LLMChain] [20.93s] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"text\": \"This Python code snippet defines a class `BaichuanLLM` that serves as a wrapper around Baichuan large language models. It imports necessary modules, sets up parameters for the model, and includes methods for validation. The class includes attributes for model configuration and API access, with methods for environmental validation. Additionally, it aims to add streaming support in the future.\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[1:chain:RefineDocumentsChain > 4:chain:LLMChain] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"text\": \"> Dict:\\n\\nvalues[\\\"baichuan_api_key\\\"] = convert_to_secret_str(\\n\\nget_from_dict_or_env(values, \\\"baichuan_api_key\\\", \\\"BAICHUAN_API_KEY\\\")\\n\\n)\\n\\nvalues[\\\"baichuan_api_host\\\"] = get_from_dict_or_env(\\n\\nvalues,\\n\\n\\\"baichuan_api_host\\\",\\n\\n\\\"BAICHUAN_API_HOST\\\",\\n\\ndefault=\\\"https://api.baichuan\\n\\n\\n\\nai.com/v1/chat/completions\\\",\\n\\n)\\n\\nreturn values\\n\\n@property\\n\\ndef _default_params(self)\\n\\n\\n\\n> Dict[str, Any]:\\n\\nreturn {\\n\\n\\\"model\\\": self.model,\\n\\n\\\"temperature\\\": self.temperature,\\n\\n\\\"top_p\\\": self.top_p,\\n\\n\\n\\n\\n\\nself.model_kwargs,\\n\\n}\\n\\ndef _post(self, request: Any) -> Any: headers = { \\\"Content-Type\\\": \\\"application/json\\\", \\\"Authorization\\\": f\\\"Bearer {self.baichuan_api_key.get_secret_value()}\\\",  # type: ignore[union-attr] } try: response = requests.post( self.baichuan_api_host,  # type: ignore[arg-type] headers=headers, json=request, timeout=self.timeout, )\",\n",
      "  \"existing_answer\": \"This Python code snippet defines a class `BaichuanLLM` that serves as a wrapper around Baichuan large language models. It imports necessary modules, sets up parameters for the model, and includes methods for validation. The class includes attributes for model configuration and API access, with methods for environmental validation. Additionally, it aims to add streaming support in the future.\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[llm/start]\u001B[0m \u001B[1m[1:chain:RefineDocumentsChain > 4:chain:LLMChain > 5:llm:OpenAIChat] Entering LLM run with input:\n",
      "\u001B[0m{\n",
      "  \"prompts\": [\n",
      "    \"Your job is to produce a final summary.\\nWe have provided an existing summary up to a certain point: This Python code snippet defines a class `BaichuanLLM` that serves as a wrapper around Baichuan large language models. It imports necessary modules, sets up parameters for the model, and includes methods for validation. The class includes attributes for model configuration and API access, with methods for environmental validation. Additionally, it aims to add streaming support in the future.\\nWe have the opportunity to refine the existing summary (only if needed) with some more context below.\\n------------\\n> Dict:\\n\\nvalues[\\\"baichuan_api_key\\\"] = convert_to_secret_str(\\n\\nget_from_dict_or_env(values, \\\"baichuan_api_key\\\", \\\"BAICHUAN_API_KEY\\\")\\n\\n)\\n\\nvalues[\\\"baichuan_api_host\\\"] = get_from_dict_or_env(\\n\\nvalues,\\n\\n\\\"baichuan_api_host\\\",\\n\\n\\\"BAICHUAN_API_HOST\\\",\\n\\ndefault=\\\"https://api.baichuan\\n\\n\\n\\nai.com/v1/chat/completions\\\",\\n\\n)\\n\\nreturn values\\n\\n@property\\n\\ndef _default_params(self)\\n\\n\\n\\n> Dict[str, Any]:\\n\\nreturn {\\n\\n\\\"model\\\": self.model,\\n\\n\\\"temperature\\\": self.temperature,\\n\\n\\\"top_p\\\": self.top_p,\\n\\n\\n\\n\\n\\nself.model_kwargs,\\n\\n}\\n\\ndef _post(self, request: Any) -> Any: headers = { \\\"Content-Type\\\": \\\"application/json\\\", \\\"Authorization\\\": f\\\"Bearer {self.baichuan_api_key.get_secret_value()}\\\",  # type: ignore[union-attr] } try: response = requests.post( self.baichuan_api_host,  # type: ignore[arg-type] headers=headers, json=request, timeout=self.timeout, )\\n------------\\nGiven the new context, refine the original summary.\\nIf the context isn't useful, return the original summary.\"\n",
      "  ]\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[llm/end]\u001B[0m \u001B[1m[1:chain:RefineDocumentsChain > 4:chain:LLMChain > 5:llm:OpenAIChat] [6.89s] Exiting LLM run with output:\n",
      "\u001B[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"The provided Python code snippet introduces a class named `BaichuanLLM` designed as a wrapper for Baichuan large language models. It encompasses necessary module imports, parameter configurations for the model, and includes methods for validation. The class incorporates attributes for model configuration and API access. Additionally, it outlines methods for environmental validation and aims to integrate streaming support in the future. The snippet also reveals a function `_default_params` which returns default parameters for the model and a `_post` method for making POST requests to a specified API endpoint, utilizing provided headers and JSON data.\",\n",
      "        \"generation_info\": null,\n",
      "        \"type\": \"Generation\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 477,\n",
      "      \"completion_tokens\": 118,\n",
      "      \"total_tokens\": 595\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[1:chain:RefineDocumentsChain > 4:chain:LLMChain] [6.89s] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"text\": \"The provided Python code snippet introduces a class named `BaichuanLLM` designed as a wrapper for Baichuan large language models. It encompasses necessary module imports, parameter configurations for the model, and includes methods for validation. The class incorporates attributes for model configuration and API access. Additionally, it outlines methods for environmental validation and aims to integrate streaming support in the future. The snippet also reveals a function `_default_params` which returns default parameters for the model and a `_post` method for making POST requests to a specified API endpoint, utilizing provided headers and JSON data.\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[1:chain:RefineDocumentsChain > 6:chain:LLMChain] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"text\": \"if response.status_code == 200: parsed_json = json.loads(response.text) return parsed_json[\\\"choices\\\"][0][\\\"message\\\"][\\\"content\\\"] else: response.raise_for_status() except Exception as e: raise ValueError(f\\\"An error has occurred: {e}\\\")\\n\\ndef _call( self, prompt: str, stop: Optional[List[str]] = None, run_manager: Optional[CallbackManagerForLLMRun] = None, **kwargs: Any, ) -> str: request = self._default_params request[\\\"messages\\\"] = [{\\\"role\\\": \\\"user\\\", \\\"content\\\": prompt}] request.update(kwargs) text = self._post(request) if stop is not None: text = enforce_stop_tokens(text, stop) return text\\n\\n@property\\n\\ndef _llm_type(self)\\n\\n\\n\\n> str:\\n\\n\\\"\\\"\\\"Return type of chat_model.\\\"\\\"\\\"\\n\\nreturn \\\"baichuan\\n\\n\\n\\nllm\\\"\",\n",
      "  \"existing_answer\": \"The provided Python code snippet introduces a class named `BaichuanLLM` designed as a wrapper for Baichuan large language models. It encompasses necessary module imports, parameter configurations for the model, and includes methods for validation. The class incorporates attributes for model configuration and API access. Additionally, it outlines methods for environmental validation and aims to integrate streaming support in the future. The snippet also reveals a function `_default_params` which returns default parameters for the model and a `_post` method for making POST requests to a specified API endpoint, utilizing provided headers and JSON data.\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[llm/start]\u001B[0m \u001B[1m[1:chain:RefineDocumentsChain > 6:chain:LLMChain > 7:llm:OpenAIChat] Entering LLM run with input:\n",
      "\u001B[0m{\n",
      "  \"prompts\": [\n",
      "    \"Your job is to produce a final summary.\\nWe have provided an existing summary up to a certain point: The provided Python code snippet introduces a class named `BaichuanLLM` designed as a wrapper for Baichuan large language models. It encompasses necessary module imports, parameter configurations for the model, and includes methods for validation. The class incorporates attributes for model configuration and API access. Additionally, it outlines methods for environmental validation and aims to integrate streaming support in the future. The snippet also reveals a function `_default_params` which returns default parameters for the model and a `_post` method for making POST requests to a specified API endpoint, utilizing provided headers and JSON data.\\nWe have the opportunity to refine the existing summary (only if needed) with some more context below.\\n------------\\nif response.status_code == 200: parsed_json = json.loads(response.text) return parsed_json[\\\"choices\\\"][0][\\\"message\\\"][\\\"content\\\"] else: response.raise_for_status() except Exception as e: raise ValueError(f\\\"An error has occurred: {e}\\\")\\n\\ndef _call( self, prompt: str, stop: Optional[List[str]] = None, run_manager: Optional[CallbackManagerForLLMRun] = None, **kwargs: Any, ) -> str: request = self._default_params request[\\\"messages\\\"] = [{\\\"role\\\": \\\"user\\\", \\\"content\\\": prompt}] request.update(kwargs) text = self._post(request) if stop is not None: text = enforce_stop_tokens(text, stop) return text\\n\\n@property\\n\\ndef _llm_type(self)\\n\\n\\n\\n> str:\\n\\n\\\"\\\"\\\"Return type of chat_model.\\\"\\\"\\\"\\n\\nreturn \\\"baichuan\\n\\n\\n\\nllm\\\"\\n------------\\nGiven the new context, refine the original summary.\\nIf the context isn't useful, return the original summary.\"\n",
      "  ]\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[llm/end]\u001B[0m \u001B[1m[1:chain:RefineDocumentsChain > 6:chain:LLMChain > 7:llm:OpenAIChat] [8.23s] Exiting LLM run with output:\n",
      "\u001B[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"The provided Python code snippet introduces a class named `BaichuanLLM` serving as a wrapper for Baichuan large language models. It includes module imports, model parameter configurations, and methods for validation. The class features attributes for model configuration and API access, along with methods for environmental validation and forthcoming streaming support integration. Additionally, it reveals a function `_default_params` returning default model parameters, a `_post` method for making POST requests to a specified API endpoint, and a `_call` method for interacting with the model, which includes handling responses and enforcing stop tokens. Finally, it incorporates a property method `_llm_type` returning the type of the chat model, specified as \\\"baichuan_llm\\\".\",\n",
      "        \"generation_info\": null,\n",
      "        \"type\": \"Generation\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 416,\n",
      "      \"completion_tokens\": 152,\n",
      "      \"total_tokens\": 568\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[1:chain:RefineDocumentsChain > 6:chain:LLMChain] [8.23s] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"text\": \"The provided Python code snippet introduces a class named `BaichuanLLM` serving as a wrapper for Baichuan large language models. It includes module imports, model parameter configurations, and methods for validation. The class features attributes for model configuration and API access, along with methods for environmental validation and forthcoming streaming support integration. Additionally, it reveals a function `_default_params` returning default model parameters, a `_post` method for making POST requests to a specified API endpoint, and a `_call` method for interacting with the model, which includes handling responses and enforcing stop tokens. Finally, it incorporates a property method `_llm_type` returning the type of the chat model, specified as \\\"baichuan_llm\\\".\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[1:chain:RefineDocumentsChain] [36.08s] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output_text\": \"The provided Python code snippet introduces a class named `BaichuanLLM` serving as a wrapper for Baichuan large language models. It includes module imports, model parameter configurations, and methods for validation. The class features attributes for model configuration and API access, along with methods for environmental validation and forthcoming streaming support integration. Additionally, it reveals a function `_default_params` returning default model parameters, a `_post` method for making POST requests to a specified API endpoint, and a `_call` method for interacting with the model, which includes handling responses and enforcing stop tokens. Finally, it incorporates a property method `_llm_type` returning the type of the chat model, specified as \\\"baichuan_llm\\\".\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'input_documents': [Document(page_content='from __future__ import annotations\\n\\nimport json import logging from typing import Any, Dict, List, Optional\\n\\nimport requests from langchain_core.callbacks import CallbackManagerForLLMRun from langchain_core.language_models.llms import LLM from langchain_core.pydantic_v1 import Field, SecretStr, root_validator from langchain_core.utils import convert_to_secret_str, get_from_dict_or_env\\n\\nfrom langchain_community.llms.utils import enforce_stop_tokens\\n\\nlogger = logging.getLogger(__name__)\\n\\nclass BaichuanLLM(LLM): # TODO: Adding streaming support. \"\"\"Wrapper around Baichuan large language models.\"\"\"\\n\\nmodel: str = \"Baichuan2-Turbo-192k\" \"\"\" Other models are available at https://platform.baichuan-ai.com/docs/api. \"\"\" temperature: float = 0.3 top_p: float = 0.95 timeout: int = 60 model_kwargs: Dict[str, Any] = Field(default_factory=dict)\\n\\nbaichuan_api_host: Optional[str] = None\\n\\nbaichuan_api_key: Optional[SecretStr] = None\\n\\n@root_validator()\\n\\ndef validate_environment(cls, values: Dict)', metadata={'source': '/Users/xiaoleizuo/opt/anaconda3/lib/python3.9/site-packages/langchain_community/llms/baichuan.py'}),\n  Document(page_content='> Dict:\\n\\nvalues[\"baichuan_api_key\"] = convert_to_secret_str(\\n\\nget_from_dict_or_env(values, \"baichuan_api_key\", \"BAICHUAN_API_KEY\")\\n\\n)\\n\\nvalues[\"baichuan_api_host\"] = get_from_dict_or_env(\\n\\nvalues,\\n\\n\"baichuan_api_host\",\\n\\n\"BAICHUAN_API_HOST\",\\n\\ndefault=\"https://api.baichuan\\n\\n\\n\\nai.com/v1/chat/completions\",\\n\\n)\\n\\nreturn values\\n\\n@property\\n\\ndef _default_params(self)\\n\\n\\n\\n> Dict[str, Any]:\\n\\nreturn {\\n\\n\"model\": self.model,\\n\\n\"temperature\": self.temperature,\\n\\n\"top_p\": self.top_p,\\n\\n\\n\\n\\n\\nself.model_kwargs,\\n\\n}\\n\\ndef _post(self, request: Any) -> Any: headers = { \"Content-Type\": \"application/json\", \"Authorization\": f\"Bearer {self.baichuan_api_key.get_secret_value()}\",  # type: ignore[union-attr] } try: response = requests.post( self.baichuan_api_host,  # type: ignore[arg-type] headers=headers, json=request, timeout=self.timeout, )', metadata={'source': '/Users/xiaoleizuo/opt/anaconda3/lib/python3.9/site-packages/langchain_community/llms/baichuan.py'}),\n  Document(page_content='if response.status_code == 200: parsed_json = json.loads(response.text) return parsed_json[\"choices\"][0][\"message\"][\"content\"] else: response.raise_for_status() except Exception as e: raise ValueError(f\"An error has occurred: {e}\")\\n\\ndef _call( self, prompt: str, stop: Optional[List[str]] = None, run_manager: Optional[CallbackManagerForLLMRun] = None, **kwargs: Any, ) -> str: request = self._default_params request[\"messages\"] = [{\"role\": \"user\", \"content\": prompt}] request.update(kwargs) text = self._post(request) if stop is not None: text = enforce_stop_tokens(text, stop) return text\\n\\n@property\\n\\ndef _llm_type(self)\\n\\n\\n\\n> str:\\n\\n\"\"\"Return type of chat_model.\"\"\"\\n\\nreturn \"baichuan\\n\\n\\n\\nllm\"', metadata={'source': '/Users/xiaoleizuo/opt/anaconda3/lib/python3.9/site-packages/langchain_community/llms/baichuan.py'})],\n 'output_text': 'The provided Python code snippet introduces a class named `BaichuanLLM` serving as a wrapper for Baichuan large language models. It includes module imports, model parameter configurations, and methods for validation. The class features attributes for model configuration and API access, along with methods for environmental validation and forthcoming streaming support integration. Additionally, it reveals a function `_default_params` returning default model parameters, a `_post` method for making POST requests to a specified API endpoint, and a `_call` method for interacting with the model, which includes handling responses and enforcing stop tokens. Finally, it incorporates a property method `_llm_type` returning the type of the chat model, specified as \"baichuan_llm\".'}"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(split_documents)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
